from flask import Flask, jsonify, render_template
from flask_socketio import SocketIO, disconnect
from flask_cors import CORS
import mediapipe as mp
import numpy as np
import base64
import cv2
import utils
from scipy.signal import find_peaks
from scipy.ndimage import gaussian_filter
from scipy.signal import butter, filtfilt

app = Flask(__name__)
CORS(app)
socketio = SocketIO(app,  cors_allowed_origins="*")

####### Image Processing #######

mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh()

video_data = []
full_video_data = []

def process_image(image_data):
    img_data = base64.b64decode(image_data)
    nparr = np.frombuffer(img_data, np.uint8)
    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    if frame is not None:
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = face_mesh.process(frame_rgb)
        if results.multi_face_landmarks:
            lmrks = utils.face_mesh_to_array(results, frame_rgb.shape[1], frame_rgb.shape[0])
            if lmrks is not None:
                bbox = utils.get_square_bbox(utils.get_bbox(lmrks, frame_rgb.shape[1], frame_rgb.shape[0]), frame_rgb.shape[1], frame_rgb.shape[0])
                x1, y1, x2, y2 = bbox
                cropped = frame_rgb[y1:y2, x1:x2]
                return cropped 
    return None

# ë°´ë“œíŒ¨ìŠ¤ í•„í„° ì„¤ì •
def butter_bandpass(lowcut, highcut, fs, order=5):
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    return b, a

def butter_bandpass_filter(data, lowcut, highcut, fs, order=2):
    b, a = butter_bandpass(lowcut, highcut, fs, order=order)
    y = filtfilt(b, a, data)
    return y

def extract_green_channel_signal(video_frames):
    green_channel_means = [frame[:, :, 1].mean() for frame in video_frames]
    smoothed_wave = gaussian_filter(green_channel_means, sigma=2)
    filtered_signal = butter_bandpass_filter(smoothed_wave, 0.67, 3.33, fps = 30, order=2)
    return np.gradient(smoothed_wave)

def calculate_hr(state, video_frames, fps=30, window_size=150, step_size=30):
    rPPG_signal = extract_green_channel_signal(video_frames)
    bpm_per_frame = []

    for start in range(0, len(rPPG_signal) - window_size, step_size):
        end = start + window_size
        segment = rPPG_signal[start:end]
        peaks, _ = find_peaks(segment, distance=10)
        if len(peaks) > 1:
            ibi = np.diff(peaks) / fps
            bpm = 60 / np.mean(ibi) if len(ibi) > 0 else np.nan
        else:
            bpm = np.nan
        bpm_per_frame.append(bpm)

    if state == "end": return bpm_per_frame
    return bpm_per_frame[-1] if bpm_per_frame else None

# Stress Index
def calculate_SI(signal, fps, window_size=150, step_size=30):
    # 1. rPPG ì‹ í˜¸ ì¶”ì¶œ
    rPPG_Signal = extract_green_channel_signal(signal)
    rppg = rPPG_Signal - np.mean(rPPG_Signal)  # DC ì»´í¬ë„ŒíŠ¸ ì œê±°

    # 2. PPI (Peak-to-Peak Interval) ì¶”ì¶œ
    peaks, _ = find_peaks(rppg, distance=fps//2)  # ì˜ˆ: 20ì€ ìµœì†Œ ê°„ê²© (ms)ì…ë‹ˆë‹¤.
    nn_intervals = np.diff(peaks) / fps  # PPIë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜

    # 3. Mode (Mo) ë° Amplitude of Mode (AMo) ê³„ì‚°
    bin_width = 0.05  # 50msë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
    hist, bin_edges = np.histogram(nn_intervals, bins=np.arange(0, np.max(nn_intervals), bin_width))
    print(f"hist : {hist}")
    print(f"bin: {bin_edges}")
    Mo = bin_edges[np.argmax(hist)]
    AMo = (np.sum((nn_intervals >= Mo - bin_width/2) & (nn_intervals < Mo + bin_width/2)) / len(nn_intervals))

    # 4. Variation range (MxDMn) ê³„ì‚°
    Mx = np.max(nn_intervals)
    Mn = np.min(nn_intervals)   
    MxDMn = Mx - Mn

    # 5. Baevsky stress index (SI) ê³„ì‚° 0~40 ì‚¬ì´ ê°’ìœ¼ë¡œ ë‚˜ì˜´
    SI = (AMo * 100) / (2 * Mo * MxDMn)
    return SI

@app.route('/')
def hello_world():
    return "FaceMind Flask Server"

@app.route('/chat')
def chatting():
    return render_template('client.html')

# connection open(start)
@socketio.on('message')
def handle_message(json):
    print("start : ", json)
    image = json.get('image', '')
    # ğŸ“Œ ì‹¬ë°•ìˆ˜ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ ì‘ì„± (dictionary í˜•ì‹ìœ¼ë¡œ return í•´ì£¼ì„¸ìš”!)
    #ex. result = calculate("start", image)
    processed_image = process_image(image)
    if processed_image is not None:
        video_data.append(processed_image)
        full_video_data.append(processed_image)
        video_array = np.array(video_data)
        if len(video_data) >= 150:
            heart_rate = calculate_hr("start", video_array)
            print('calculated hr: ', heart_rate)
            del video_data[:30]
    result = {'heartrate' : heart_rate}
    socketio.send(result) # clientì—ê²Œ ë©”ì„¸ì§€ ì „ì†¡
    socketio.sleep(0.5)

# connection ë„ì¤‘ì— image ë³´ë‚´ê¸°
@socketio.on('ingSending')
def example_send(json):
    print("ing : ", json)
    image = json.get('image', '')
    # ğŸ“Œ ì‹¬ë°•ìˆ˜ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ ì‘ì„± (dictionary í˜•ì‹ìœ¼ë¡œ return í•´ì£¼ì„¸ìš”!)
    #ex. result = calculate("ing", image)
    processed_image = process_image(image)
    if processed_image is not None:
        video_data.append(processed_image)
        full_video_data.append(processed_image)
        video_array = np.array(video_data)
        if len(video_data) >= 150:
            heart_rate = calculate_hr("ing",video_array)
            print('calculated hr: ', heart_rate)
            del video_data[:30]
    result = {'heartrate' : heart_rate}
    socketio.send(result) # clientì—ê²Œ ë©”ì„¸ì§€ ì „ì†¡
    socketio.sleep(0.5)

# connection ë‹«ê¸° ì „ì— ìµœì¢… ê²°ê³¼ ë°˜í™˜í•œ í›„ connection ì¢…ë£Œ
@socketio.on('closeSending')
def disconnect_socket(json):
    print("close :", json)
    image = json.get('image', '')
    # ğŸ“Œ ìµœì¢…ê²°ê³¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ ì‘ì„± (dictionary í˜•ì‹ìœ¼ë¡œ return í•´ì£¼ì„¸ìš”!)
    #ex. result = calculate("end", image)
    processed_image = process_image(image)
    if processed_image is not None:
        video_data.append(processed_image)
        full_video_data_array = np.array(full_video_data)
        full_video_data.append(processed_image)
        heart_rate = calculate_hr("end", full_video_data)
        print('calculated hr: ', heart_rate)
        video_data.pop(0)
    min_hr = min(heart_rate)
    max_hr = max(heart_rate)
    mean_hr = np.mean(heart_rate)
    stress_index = calculate_SI(full_video_data_array, fps = 30)
    result = {
        "min_hr" : min_hr,
        "max_hr" : max_hr,
        "mean_hr" : mean_hr,
        "stress_index" : stress_index
    }
    socketio.send(result)
    socketio.sleep(0.5)
    disconnect() # ì—°ê²° í•´ì œ

if __name__ == '__main__':
    socketio.run(app, host='0.0.0.0', port=5000)